### 阅读英文多媒体技术讨论和实战记录

> @source https://jpetazzo.github.io/2020/06/27/streaming-part-4-linux/ 系列

#### 1. Using a phone or a DSLR as a webcam 

- Sending OBS output to a virtual webcam (or to a screen and then capturing that screen) is also a good way to grab that output and then do whatever you want with it. I use GPU acceleration to encode simultaneously 4 different bitrates, send them all to a broadcast server, and save the highest one to disk, for instance. (More on that later.)

- 手机和单反相机的摄像头作为webcamera, 基于web系统视频系统

- ffmpeg tries to read+convert+write frames as fast as it can, without any concern for their supposed play speed. You might see in the output that it’s operating at “1.2x” because it computes that it’s processing 30 frames per second on a 25 frames per second video stream. Whatever.

- OBS “linuxbrowser” plugin

- AVC的规格bai分为三等，从低到高分别为：Baseline、Main、High。
  Baseline（最低zhiProfile）级别支持daoI/P 帧，zhuan只支持无交错（Progressive）和CAVLC，一般用于低阶或shu需要额外容错的应用，比如视频通话、手机视频等；
  Main（主要Profile）级别提供I/P/B 帧，支持无交错（Progressive）和交错（Interlaced），同样提供对于CAVLC 和CABAC 的支持，用于主流消费类电子产品规格如低解码（相对而言）的mp4、便携的视频播放器、PSP和Ipod等；
  High（高端Profile，也叫FRExt）级别在Main的基础上增加了8x8 内部预测、自定义量化、无损视频编码和更多的YUV 格式（如4：4：4）用于广播及视频碟片存储（蓝光影片），高清电视的应用.

- 三种帧类型 
  IF——I-frame的缩写，即关键帧。关键帧是构成一个帧组（GOP，Group of Picture）的第一个帧。IF保留了一个场景的所有信息。压缩比为1：7。
  PF——P-frame的缩写，即未来单项预测帧，只储存与之前一个已解压画面的差值。压缩比为1：20。
  BF——B-frame的缩写，即双向预测帧，除了参考之前解压过了的画面外，亦会参考后面一帧中的画面信息。压缩比为1：50。 B-Frame（在 MPEG-4 里面正确的名称是 B-VOP）的预测模式有四种.

- *GOP*（Group of Pictures）策略影响编码质量，所谓*GOP*.一个*GOP*就是一组连续的画面。*GOP*是序列中的一个图片集，用来辅助随机存取。*GOP*的第一个*图像*必须为I帧，这样就能保证*GOP*不需要参考其他*图像*，可以独立解码。

- except if you already have experience running desktop applications in containers.

  The Dockerfiles and the Compose file that I use is available on my [obs-docker](https://github.com/jpetazzo/obs-docker/) repository on GitHub.

  https://github.com/jpetazzo/obs-docker/

- 两种应用情况: 视频会议video calls, 多媒体直播 streaming

  - video call,实时 < 0.5s, 要加入其他参与人的音频等,规模一般是几人,几十人等
  - streaming, 一个人面对成千上万人,一般延时比较大,几秒中,通常的方案会是20-30秒的decay.附加听众文本交互,

-  use-case that I’m optimizing for

- 最后,作者选择了Ant Media Server作为它的直播和交互的工具,企业版本,付费模式.

  - java 开发
  - github,上面有开源的版本可以下载
  - https://github.com/ant-media/Ant-Media-Server



#### 2. 开发库

-  [IP Webcam](https://play.google.com/store/apps/details?id=com.pas.webcam). 让手机成为一个web视频播放服务设备

- [obs-websocket](https://obsproject.com/forum/resources/obs-websocket-remote-control-obs-studio-from-websockets.466/), a plugin to allow OBS to be controlled through WebSockets. 

- use [obs-websocket-py](https://github.com/Elektordi/obs-websocket-py), a Python client library to interface with that plugin; and a little custom script called [owc](https://github.com/jpetazzo/obs-docker/blob/main/bin/owc) to invoke that library from the command line. 

- [ALSA](https://en.wikipedia.org/wiki/Advanced_Linux_Sound_Architecture) loopback device. ALSA is a popular API to access audio input/output on Linux.

- While many applications nowadays use PulseAudio or [JACK](https://en.wikipedia.org/wiki/JACK_Audio_Connection_Kit) to access audio interfaces, PulseAudio and JACK themselves generally use ALSA to communicate with the hardware. ALSA is to audio what V4L2 is to video: they’re both low-level interfaces to access respectively audio and video input/output devices.

- On Linux, the usual way to deal with multi-monitor setups is to use the RandR extension (unless you use Wayland, but I’m going to leave that aside). There is a command-line utility `xrandr`, a crude but effective GUI called `arandr`, and you can use a tool like `autorandr` to automatically switch modes when screens are connected and disconnected.

- ### [Jitsi](https://jitsi.org/)

  Jitsi is an open source video conferencing system. You can deploy it on your own servers, and there is also a free option, [Jitsi Meet](https://jpetazzo.github.io/2020/06/04/streaming-part-3-obs-streaming/meet.jit.si/).

